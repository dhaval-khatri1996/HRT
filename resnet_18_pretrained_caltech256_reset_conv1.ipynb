{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TScN3Juf3yiR"
      },
      "source": [
        "Model: Resnet-18\n",
        "Dataset: caltech 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SHeG1o11ARm",
        "outputId": "fa425707-ff0e-42b7-daae-74c83e1a9cc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------\n",
        "# 1️⃣ Imports and device setup\n",
        "# ------------------------------\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import urllib.request\n",
        "import tarfile\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torchvision.models import ResNet18_Weights\n",
        "\n",
        "SEED = 7777\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "ENYPMzLp1Tor"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# 2️⃣ Parameters\n",
        "# ------------------------------\n",
        "N_EDGE_EPOCHS = 4        # epochs to feed edge maps\n",
        "N_FULL_SIZE_AFTER = 10    #epochs to train on smaller image\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS =15\n",
        "LEARNING_RATE = 0.001\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "qBixaYl81ULc"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# 3️⃣ Edge transform\n",
        "# ------------------------------\n",
        "class EdgeTransform:\n",
        "    def __call__(self, img):\n",
        "        img_np = np.array(img)\n",
        "        gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
        "        grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "        grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "        edges = np.sqrt(grad_x**2 + grad_y**2)\n",
        "        edges = np.clip(edges / edges.max(), 0, 1)\n",
        "        edges = np.stack([edges]*3, axis=0)\n",
        "        return torch.tensor(edges, dtype=torch.float32)\n",
        "\n",
        "edge_transform = EdgeTransform()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "frOJs8ny3rpv"
      },
      "outputs": [],
      "source": [
        "def seed_worker(worker_id):\n",
        "    worker_seed = SEED + worker_id\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "j1dhM2QyADyL",
        "outputId": "16015f32-7cd6-435d-bb5e-79e24edf4e14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'import shutil\\nfolder = \"/content/caltech256/256_ObjectCategories_preprocessed\"\\nif os.path.exists(folder):\\n    shutil.rmtree(folder)   # recursively deletes folder and all subfolders/files\\n    print(f\"{folder} deleted successfully!\")\\nelse:\\n    print(\"Folder does not exist\")'"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''import shutil\n",
        "folder = \"/content/caltech256/256_ObjectCategories_preprocessed\"\n",
        "if os.path.exists(folder):\n",
        "    shutil.rmtree(folder)   # recursively deletes folder and all subfolders/files\n",
        "    print(f\"{folder} deleted successfully!\")\n",
        "else:\n",
        "    print(\"Folder does not exist\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2wx82Ha3rpw",
        "outputId": "74a23419-e996-4b10-c678-bbea468cbde4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessed images already exist, skipping preprocessing.\n"
          ]
        }
      ],
      "source": [
        "# Download Caltech256\n",
        "import os\n",
        "import urllib.request\n",
        "import tarfile\n",
        "from PIL import Image, UnidentifiedImageError # Import UnidentifiedImageError\n",
        "from tqdm import tqdm\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "url = 'https://data.caltech.edu/records/nyy15-4j048/files/256_ObjectCategories.tar'\n",
        "data_dir = '/content/caltech256'\n",
        "\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "tar_path = os.path.join(data_dir, '256_ObjectCategories.tar')\n",
        "if not os.path.exists(tar_path):\n",
        "    print(\"Downloading Caltech256...\")\n",
        "    urllib.request.urlretrieve(url, tar_path)\n",
        "    print(\"Download complete!\")\n",
        "\n",
        "# Extract\n",
        "if not os.path.exists(os.path.join(data_dir, '256_ObjectCategories')):\n",
        "    print(\"Extracting...\")\n",
        "    with tarfile.open(tar_path) as tar:\n",
        "        tar.extractall(path=data_dir)\n",
        "    print(\"Extraction complete!\")\n",
        "\n",
        "  # -------------------------------\n",
        "# Preprocess: resize + center crop + save\n",
        "# -------------------------------\n",
        "preprocessed_dir = os.path.join(data_dir, '256_ObjectCategories_preprocessed')\n",
        "extracted_dir = os.path.join(data_dir, '256_ObjectCategories') # Define extracted_dir\n",
        "if not os.path.exists(preprocessed_dir):\n",
        "    print(\"Preprocessing images (resize + center crop)...\")\n",
        "\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),      # resize shorter side\n",
        "        transforms.CenterCrop(224)   # crop center 224x224\n",
        "    ])\n",
        "\n",
        "    # Gather all image paths and corresponding output paths\n",
        "    all_images = []\n",
        "    for class_name in os.listdir(extracted_dir):\n",
        "        class_in = os.path.join(extracted_dir, class_name)\n",
        "        class_out = os.path.join(preprocessed_dir, class_name)\n",
        "        os.makedirs(class_out, exist_ok=True)\n",
        "\n",
        "        for img_name in os.listdir(class_in):\n",
        "            img_path = os.path.join(class_in, img_name)\n",
        "            out_path = os.path.join(class_out, img_name)\n",
        "            if os.path.isfile(img_path): # Check if it's a file\n",
        "                all_images.append((img_path, out_path))\n",
        "\n",
        "    # Single progress bar for all images\n",
        "    for img_path, out_path in tqdm(all_images, desc=\"Preprocessing images\"):\n",
        "        try:\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "            img = preprocess(img)\n",
        "            img.save(out_path)\n",
        "        except UnidentifiedImageError:\n",
        "            print(f\"Skipping {img_path}: Cannot identify image file\")\n",
        "\n",
        "\n",
        "    print(\"Preprocessing complete!\")\n",
        "else:\n",
        "    print(\"Preprocessed images already exist, skipping preprocessing.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "NM2z25kG1hkB"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# 4️⃣ Data loading with subset\n",
        "# ------------------------------\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "\n",
        "def load_data(batch_size=BATCH_SIZE, subset_percent=None):\n",
        "\n",
        "    # Define a basic transform to convert PIL Images to Tensors\n",
        "    basic_transform = transforms.ToTensor()\n",
        "\n",
        "    full_dataset = datasets.ImageFolder(os.path.join(data_dir,'256_ObjectCategories_preprocessed'), transform=basic_transform)\n",
        "\n",
        "    # Train/val split: 80/20\n",
        "    train_size = int(0.8 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size\n",
        "    trainset_full, test_set = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "\n",
        "    if subset_percent is not None:\n",
        "        subset_size = int(len(trainset_full) * subset_percent)\n",
        "        indices = torch.randperm(len(trainset_full))[:subset_size]\n",
        "        train_set = Subset(trainset_full, indices)\n",
        "    else:\n",
        "        train_set = trainset_full\n",
        "\n",
        "    trainloader = DataLoader(\n",
        "                            train_set,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=True,\n",
        "                            worker_init_fn=seed_worker\n",
        "                            )\n",
        "    testloader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "    return trainloader, testloader, len(full_dataset.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "bdGAFJuQ44Ow"
      },
      "outputs": [],
      "source": [
        "# Example usage: 10% of training data\n",
        "trainloader, testloader, num_classes = load_data(subset_percent =1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzlKwXgt7hil",
        "outputId": "2ad4d4f6-d9db-49a3-ad71-ba07dcb8a2b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "766"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(trainloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "myqAaXOZ29rp"
      },
      "outputs": [],
      "source": [
        "def resnet18(output_classes = 256, pretrained = False):\n",
        "    # Load ResNet18 without pretrained weights\n",
        "    if pretrained:\n",
        "        model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "    else:\n",
        "        model = models.resnet18(weights = None)\n",
        "\n",
        "    model.fc = nn.Linear(model.fc.in_features, output_classes)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "zNK9PtuW3Co_"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# 6️⃣ Training function\n",
        "# ------------------------------\n",
        "def train_one_epoch(model, loader, optimizer, criterion, epoch_num, n_edge_epochs=N_EDGE_EPOCHS, blur_factor = 0.0):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    for images, labels in loader:\n",
        "\n",
        "        if epoch_num < n_edge_epochs:\n",
        "            # Edge transform\n",
        "            images = torch.stack([edge_transform(img.permute(1,2,0).numpy()*255) for img in images])\n",
        "        elif epoch_num < N_FULL_SIZE_AFTER and blur_factor !=0:\n",
        "            images = torch.stack([\n",
        "                transforms.Compose([\n",
        "                transforms.GaussianBlur(kernel_size=5, sigma=min(4, blur_factor)),\n",
        "                ])(img) for img in images])\n",
        "\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return running_loss / total, correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "XxGRo6Hi3IJX"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# 7️⃣ Validation function (concise Top-1 & Top-5)\n",
        "# ------------------------------\n",
        "def validate(model, loader, criterion, topk=(1,5)):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = [0] * len(topk)\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            val_loss += criterion(outputs, labels).item() * labels.size(0)\n",
        "            total += labels.size(0)\n",
        "\n",
        "            maxk = max(topk)\n",
        "            _, pred = outputs.topk(maxk, dim=1, largest=True, sorted=True)\n",
        "            pred = pred.t()\n",
        "            matches = pred.eq(labels.view(1, -1).expand_as(pred))\n",
        "\n",
        "            for i, k in enumerate(topk):\n",
        "                correct[i] += matches[:k].reshape(-1).float().sum().item()\n",
        "\n",
        "    val_loss /= total\n",
        "    accuracies = [c / total for c in correct]\n",
        "    return val_loss, accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "RwH_gTqLFN0x"
      },
      "outputs": [],
      "source": [
        "def freeze_high_layers(model):\n",
        "    # Freeze layer3, layer4, and layer2\n",
        "    for name, param in model.named_parameters():\n",
        "        if \"layer4\" in name or \"layer3\" in name:\n",
        "            param.requires_grad = False\n",
        "        else:\n",
        "            param.requires_grad = True\n",
        "\n",
        "def unfreeze_all_layers(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "5ngXIxcR3rpy"
      },
      "outputs": [],
      "source": [
        "def mean_abs_activation(model, loader, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    Prints mean absolute activation per layer for a single batch.\n",
        "    Works safely for ResNet-18, including avgpool and fc.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    x, _ = next(iter(loader))\n",
        "    x = x.to(device)\n",
        "    activations = {}\n",
        "    round_to = 4\n",
        "    with torch.no_grad():\n",
        "        out = model.conv1(x); activations[\"conv1\"] = round(out.abs().mean().item(),round_to)\n",
        "        out = model.layer1(out); activations[\"layer1\"] = round(out.abs().mean().item(),round_to)\n",
        "        out = model.layer2(out); activations[\"layer2\"] = round(out.abs().mean().item(),round_to)\n",
        "        out = model.layer3(out); activations[\"layer3\"] = round(out.abs().mean().item(),round_to)\n",
        "        out = model.layer4(out); activations[\"layer4\"] = round(out.abs().mean().item(),round_to)\n",
        "        out = model.avgpool(out); activations[\"avgpool\"] = round(out.abs().mean().item(),round_to)\n",
        "        out = torch.flatten(out, 1); out = model.fc(out); activations[\"fc\"] = round(out.abs().mean().item(),round_to)\n",
        "    print(activations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "3hbi1khLI3j2"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model, optimizer, epoch,\n",
        "                    method_name=\"method1\", save_dir=\"checkpoints\"):\n",
        "    \"\"\"\n",
        "    Saves a PyTorch model checkpoint at the end of training.\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    filename = f\"{method_name}_epoch_{epoch}.pth\"\n",
        "    path = os.path.join(save_dir, filename)\n",
        "\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'method_name': method_name\n",
        "    }, path)\n",
        "\n",
        "    print(f\"Saved checkpoint for {method_name} at epoch {epoch}: {path}\")\n",
        "    return path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "6P2zxN2uaqIB"
      },
      "outputs": [],
      "source": [
        "#Function to reset a layer\n",
        "def reset_block(block):\n",
        "    for m in block.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            nn.init.constant_(m.weight, 1)\n",
        "            nn.init.constant_(m.bias, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL_Gqm2O3M5E",
        "outputId": "2b6ccbce-4894-4d8d-9d8b-4720d166ef88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.) Baseline\n",
            "Epoch 1/15 | Train Loss: 2.9962, Acc: 0.3692 | Val Loss: 2.7155, Acc: 0.3958, Top_5_acc : 0.6421 \n",
            "{'conv1': 0.4571, 'layer1': 0.8063, 'layer2': 0.2641, 'layer3': 0.1939, 'layer4': 0.5968, 'avgpool': 0.5968, 'fc': 4.7715}\n",
            "Epoch 2/15 | Train Loss: 1.4068, Acc: 0.6508 | Val Loss: 1.7708, Acc: 0.5867, Top_5_acc : 0.8030 \n",
            "{'conv1': 0.5775, 'layer1': 0.9516, 'layer2': 0.286, 'layer3': 0.2484, 'layer4': 0.7473, 'avgpool': 0.7473, 'fc': 7.2833}\n",
            "Epoch 3/15 | Train Loss: 0.7373, Acc: 0.8074 | Val Loss: 1.7444, Acc: 0.5978, Top_5_acc : 0.8040 \n",
            "{'conv1': 0.5663, 'layer1': 0.8582, 'layer2': 0.2496, 'layer3': 0.1899, 'layer4': 1.0496, 'avgpool': 1.0496, 'fc': 11.4627}\n",
            "Epoch 4/15 | Train Loss: 0.3124, Acc: 0.9185 | Val Loss: 1.6858, Acc: 0.6297, Top_5_acc : 0.8255 \n",
            "{'conv1': 0.613, 'layer1': 0.9477, 'layer2': 0.2808, 'layer3': 0.2035, 'layer4': 0.6993, 'avgpool': 0.6993, 'fc': 8.1187}\n",
            "Epoch 5/15 | Train Loss: 0.1442, Acc: 0.9657 | Val Loss: 1.6120, Acc: 0.6514, Top_5_acc : 0.8381 \n",
            "{'conv1': 0.5969, 'layer1': 0.9047, 'layer2': 0.2743, 'layer3': 0.1992, 'layer4': 0.7396, 'avgpool': 0.7396, 'fc': 8.8924}\n",
            "Epoch 6/15 | Train Loss: 0.0661, Acc: 0.9862 | Val Loss: 1.5661, Acc: 0.6728, Top_5_acc : 0.8507 \n",
            "{'conv1': 0.6915, 'layer1': 0.9864, 'layer2': 0.2853, 'layer3': 0.2241, 'layer4': 1.0121, 'avgpool': 1.0121, 'fc': 12.2553}\n",
            "Epoch 7/15 | Train Loss: 0.0408, Acc: 0.9929 | Val Loss: 1.4460, Acc: 0.6851, Top_5_acc : 0.8579 \n",
            "{'conv1': 0.6384, 'layer1': 0.9379, 'layer2': 0.2674, 'layer3': 0.204, 'layer4': 0.7228, 'avgpool': 0.7228, 'fc': 8.6404}\n",
            "Epoch 8/15 | Train Loss: 0.0375, Acc: 0.9931 | Val Loss: 1.6808, Acc: 0.6650, Top_5_acc : 0.8425 \n",
            "{'conv1': 0.6044, 'layer1': 0.9623, 'layer2': 0.2826, 'layer3': 0.2008, 'layer4': 0.6738, 'avgpool': 0.6738, 'fc': 7.996}\n",
            "Epoch 9/15 | Train Loss: 0.0242, Acc: 0.9964 | Val Loss: 1.4061, Acc: 0.6998, Top_5_acc : 0.8620 \n",
            "{'conv1': 0.6033, 'layer1': 0.9103, 'layer2': 0.259, 'layer3': 0.1834, 'layer4': 0.6679, 'avgpool': 0.6679, 'fc': 7.7915}\n",
            "Epoch 10/15 | Train Loss: 0.0066, Acc: 0.9997 | Val Loss: 1.2909, Acc: 0.7123, Top_5_acc : 0.8736 \n",
            "{'conv1': 0.5965, 'layer1': 0.9296, 'layer2': 0.2645, 'layer3': 0.1739, 'layer4': 0.6516, 'avgpool': 0.6516, 'fc': 7.2518}\n",
            "Epoch 11/15 | Train Loss: 0.0055, Acc: 0.9998 | Val Loss: 1.2527, Acc: 0.7187, Top_5_acc : 0.8778 \n",
            "{'conv1': 0.6357, 'layer1': 0.9542, 'layer2': 0.2806, 'layer3': 0.1993, 'layer4': 0.646, 'avgpool': 0.646, 'fc': 6.8925}\n",
            "Epoch 12/15 | Train Loss: 0.0046, Acc: 0.9997 | Val Loss: 1.2334, Acc: 0.7254, Top_5_acc : 0.8814 \n",
            "{'conv1': 0.5897, 'layer1': 0.9073, 'layer2': 0.2597, 'layer3': 0.1841, 'layer4': 0.6854, 'avgpool': 0.6854, 'fc': 7.0096}\n",
            "Epoch 13/15 | Train Loss: 0.0030, Acc: 0.9999 | Val Loss: 1.2000, Acc: 0.7272, Top_5_acc : 0.8845 \n",
            "{'conv1': 0.5943, 'layer1': 0.8984, 'layer2': 0.256, 'layer3': 0.1908, 'layer4': 0.6629, 'avgpool': 0.6629, 'fc': 6.5177}\n",
            "Epoch 14/15 | Train Loss: 0.0027, Acc: 0.9998 | Val Loss: 1.1946, Acc: 0.7280, Top_5_acc : 0.8829 \n",
            "{'conv1': 0.5883, 'layer1': 0.8595, 'layer2': 0.2458, 'layer3': 0.1788, 'layer4': 0.6728, 'avgpool': 0.6728, 'fc': 6.4209}\n",
            "Epoch 15/15 | Train Loss: 0.0027, Acc: 0.9999 | Val Loss: 1.1899, Acc: 0.7315, Top_5_acc : 0.8835 \n",
            "{'conv1': 0.5999, 'layer1': 0.8757, 'layer2': 0.2489, 'layer3': 0.1843, 'layer4': 0.664, 'avgpool': 0.664, 'fc': 6.2513}\n",
            "Best run ---> val_acc : 0.7315 |Top5_acc : 0.8835 |val_loss : 1.1899\n",
            "2.)Edge + freeze\n",
            "Epoch 1/15 | Train Loss: 3.5936, Acc: 0.2974 | Val Loss: 6.5143, Acc: 0.0472, Top_5_acc : 0.1058 \n",
            "{'conv1': 0.3832, 'layer1': 0.6953, 'layer2': 0.1987, 'layer3': 0.1519, 'layer4': 1.1731, 'avgpool': 1.1731, 'fc': 9.7161}\n",
            "Epoch 2/15 | Train Loss: 1.8013, Acc: 0.5866 | Val Loss: 7.6393, Acc: 0.0436, Top_5_acc : 0.1067 \n",
            "{'conv1': 0.5025, 'layer1': 0.8552, 'layer2': 0.204, 'layer3': 0.147, 'layer4': 0.9432, 'avgpool': 0.9432, 'fc': 9.5753}\n",
            "Epoch 3/15 | Train Loss: 1.3460, Acc: 0.6742 | Val Loss: 7.0747, Acc: 0.0742, Top_5_acc : 0.1532 \n",
            "{'conv1': 0.5971, 'layer1': 0.9407, 'layer2': 0.2201, 'layer3': 0.1522, 'layer4': 0.8175, 'avgpool': 0.8175, 'fc': 9.2188}\n",
            "Epoch 4/15 | Train Loss: 1.0920, Acc: 0.7296 | Val Loss: 7.4020, Acc: 0.0622, Top_5_acc : 0.1377 \n",
            "{'conv1': 0.6283, 'layer1': 0.9115, 'layer2': 0.2401, 'layer3': 0.1564, 'layer4': 0.749, 'avgpool': 0.749, 'fc': 9.0553}\n",
            "Epoch 5/15 | Train Loss: 1.5979, Acc: 0.6108 | Val Loss: 1.8045, Acc: 0.5764, Top_5_acc : 0.7978 \n",
            "{'conv1': 0.5608, 'layer1': 0.8693, 'layer2': 0.2477, 'layer3': 0.2053, 'layer4': 0.5096, 'avgpool': 0.5096, 'fc': 8.2926}\n",
            "Epoch 6/15 | Train Loss: 0.7315, Acc: 0.8036 | Val Loss: 1.7154, Acc: 0.6085, Top_5_acc : 0.8290 \n",
            "{'conv1': 0.6494, 'layer1': 0.978, 'layer2': 0.2636, 'layer3': 0.2366, 'layer4': 0.5047, 'avgpool': 0.5047, 'fc': 8.4356}\n",
            "Epoch 7/15 | Train Loss: 0.3178, Acc: 0.9131 | Val Loss: 1.5425, Acc: 0.6630, Top_5_acc : 0.8437 \n",
            "{'conv1': 0.6875, 'layer1': 0.9981, 'layer2': 0.2624, 'layer3': 0.2786, 'layer4': 0.5224, 'avgpool': 0.5224, 'fc': 8.9118}\n",
            "Epoch 8/15 | Train Loss: 0.1337, Acc: 0.9666 | Val Loss: 1.5340, Acc: 0.6738, Top_5_acc : 0.8665 \n",
            "{'conv1': 0.6308, 'layer1': 0.973, 'layer2': 0.256, 'layer3': 0.2046, 'layer4': 0.5761, 'avgpool': 0.5761, 'fc': 9.7864}\n",
            "Epoch 9/15 | Train Loss: 0.0689, Acc: 0.9842 | Val Loss: 1.4074, Acc: 0.6908, Top_5_acc : 0.8657 \n",
            "{'conv1': 0.6364, 'layer1': 0.967, 'layer2': 0.2614, 'layer3': 0.2194, 'layer4': 0.499, 'avgpool': 0.499, 'fc': 8.4423}\n",
            "Epoch 10/15 | Train Loss: 0.0295, Acc: 0.9953 | Val Loss: 1.1408, Acc: 0.7409, Top_5_acc : 0.8973 \n",
            "{'conv1': 0.5933, 'layer1': 0.9338, 'layer2': 0.2504, 'layer3': 0.1994, 'layer4': 0.5209, 'avgpool': 0.5209, 'fc': 8.5702}\n",
            "Epoch 11/15 | Train Loss: 0.0123, Acc: 0.9988 | Val Loss: 1.1444, Acc: 0.7475, Top_5_acc : 0.8979 \n",
            "{'conv1': 0.6138, 'layer1': 0.9369, 'layer2': 0.2461, 'layer3': 0.193, 'layer4': 0.5608, 'avgpool': 0.5608, 'fc': 8.9335}\n",
            "Epoch 12/15 | Train Loss: 0.0086, Acc: 0.9993 | Val Loss: 1.0222, Acc: 0.7692, Top_5_acc : 0.9111 \n",
            "{'conv1': 0.5972, 'layer1': 0.91, 'layer2': 0.2452, 'layer3': 0.1797, 'layer4': 0.6349, 'avgpool': 0.6349, 'fc': 9.8066}\n",
            "Epoch 13/15 | Train Loss: 0.0037, Acc: 0.9998 | Val Loss: 0.9861, Acc: 0.7712, Top_5_acc : 0.9151 \n",
            "{'conv1': 0.5606, 'layer1': 0.8841, 'layer2': 0.2369, 'layer3': 0.171, 'layer4': 0.5888, 'avgpool': 0.5888, 'fc': 8.8302}\n",
            "Epoch 14/15 | Train Loss: 0.0031, Acc: 0.9998 | Val Loss: 0.9759, Acc: 0.7730, Top_5_acc : 0.9144 \n",
            "{'conv1': 0.5514, 'layer1': 0.9206, 'layer2': 0.2525, 'layer3': 0.1855, 'layer4': 0.618, 'avgpool': 0.618, 'fc': 9.09}\n",
            "Epoch 15/15 | Train Loss: 0.0026, Acc: 0.9999 | Val Loss: 0.9703, Acc: 0.7762, Top_5_acc : 0.9141 \n",
            "{'conv1': 0.5449, 'layer1': 0.9046, 'layer2': 0.2477, 'layer3': 0.1826, 'layer4': 0.6197, 'avgpool': 0.6197, 'fc': 9.0263}\n",
            "Best run ---> val_acc : 0.7762 |Top5_acc : 0.9141 |val_loss : 0.9703\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------\n",
        "# 8️⃣ Training loop (piecewise)\n",
        "# ------------------------------\n",
        "train_losses, val_losses = [[],[]], [[],[]]\n",
        "train_accs, val_accs = [[],[]], [[],[]]\n",
        "top5_accs = [[],[]]\n",
        "\n",
        "print(\"1.) Baseline\")\n",
        "model = resnet18(num_classes, pretrained= True).to(DEVICE)\n",
        "\n",
        "reset_block(model.conv1)\n",
        "optimizer = optim.Adam([\n",
        "              {'params': model.conv1.parameters(), 'lr': 1e-3,  'weight_decay': 1e-4},\n",
        "              {'params': model.layer1.parameters(), 'lr': 1e-5,  'weight_decay': 1e-4},\n",
        "              {'params': model.layer2.parameters(), 'lr': 5e-5,  'weight_decay': 1e-4},\n",
        "              {'params': model.layer3.parameters(), 'lr': 1e-4,  'weight_decay': 1e-4},\n",
        "              {'params': model.layer4.parameters(), 'lr': 3e-4,  'weight_decay': 1e-4},  #fine-tune\n",
        "              {'params': model.fc.parameters(),    'lr': 1e-3,  'weight_decay': 1e-4},  # new classifier\n",
        "          ])\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=(EPOCHS), eta_min=1e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "min_loss, val_acc_at_best_epoch, top5_acc_at_best_epoch = 100,100,100\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train_one_epoch(model, trainloader, optimizer, criterion, epoch, 0)\n",
        "    val_loss, [val_acc, top5_acc] = validate(model, testloader, criterion)\n",
        "\n",
        "    train_losses[0].append(train_loss)\n",
        "    val_losses[0].append(val_loss)\n",
        "    train_accs[0].append(train_acc)\n",
        "    val_accs[0].append(val_acc)\n",
        "    top5_accs[0].append(top5_acc)\n",
        "\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, Top_5_acc : {top5_acc:.4f} \")\n",
        "    mean_abs_activation(model, trainloader)\n",
        "\n",
        "    scheduler.step()\n",
        "    \n",
        "    if(min_loss > val_loss):\n",
        "        min_loss = val_loss\n",
        "        val_acc_at_best_epoch = val_acc\n",
        "        top5_acc_at_best_epoch = top5_acc\n",
        "\n",
        "print(f\"Best run ---> val_acc : {val_acc_at_best_epoch:.4f} |\"\n",
        "      f\"Top5_acc : {top5_acc_at_best_epoch:.4f} |\"\n",
        "      f\"val_loss : {min_loss:.4f}\")\n",
        "\n",
        "\n",
        "print(\"2.)Edge + freeze\")\n",
        "model = resnet18(num_classes, pretrained= True).to(DEVICE)\n",
        "reset_block(model.conv1)\n",
        "optimizer = optim.Adam([\n",
        "              {'params': model.conv1.parameters(), 'lr': 1e-3,  'weight_decay': 1e-4},\n",
        "              {'params': model.layer1.parameters(), 'lr': 1e-5,  'weight_decay': 1e-4},\n",
        "              {'params': model.layer2.parameters(), 'lr': 5e-5,  'weight_decay': 1e-4},\n",
        "              {'params': model.layer3.parameters(), 'lr': 1e-4,  'weight_decay': 1e-4},\n",
        "              {'params': model.layer4.parameters(), 'lr': 3e-4,  'weight_decay': 1e-4},  #fine-tune\n",
        "              {'params': model.fc.parameters(),    'lr': 1e-3,  'weight_decay': 1e-4},  # new classifier\n",
        "          ])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "min_loss, val_acc_at_best_epoch, top5_acc_at_best_epoch = 100,100,100\n",
        "\n",
        "freeze_high_layers(model)\n",
        "for epoch in range(EPOCHS):\n",
        "    if(epoch == N_EDGE_EPOCHS):\n",
        "        unfreeze_all_layers(model)\n",
        "        optimizer = optim.Adam([\n",
        "              {'params': model.conv1.parameters(), 'lr': 1e-3,  'weight_decay': 1e-4},\n",
        "              {'params': model.layer1.parameters(), 'lr': 1e-5,  'weight_decay': 1e-4},\n",
        "              {'params': model.layer2.parameters(), 'lr': 5e-5,  'weight_decay': 1e-4},\n",
        "              {'params': model.layer3.parameters(), 'lr': 1e-4,  'weight_decay': 1e-4},\n",
        "              {'params': model.layer4.parameters(), 'lr': 3e-4,  'weight_decay': 1e-4},  #fine-tune\n",
        "              {'params': model.fc.parameters(),    'lr': 1e-3,  'weight_decay': 1e-4},  # new classifier\n",
        "          ])\n",
        "        scheduler = CosineAnnealingLR(optimizer, T_max=(EPOCHS-N_EDGE_EPOCHS), eta_min=1e-5)\n",
        "    train_loss, train_acc = train_one_epoch(model, trainloader, optimizer, criterion, epoch, n_edge_epochs = N_EDGE_EPOCHS)\n",
        "    val_loss, [val_acc, top5_acc] = validate(model, testloader, criterion)\n",
        "\n",
        "    train_losses[1].append(train_loss)\n",
        "    val_losses[1].append(val_loss)\n",
        "    train_accs[1].append(train_acc)\n",
        "    val_accs[1].append(val_acc)\n",
        "    top5_accs[1].append(top5_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, Top_5_acc : {top5_acc:.4f} \")\n",
        "    mean_abs_activation(model, trainloader)\n",
        "\n",
        "    \n",
        "    if(epoch >= N_EDGE_EPOCHS):\n",
        "        scheduler.step()\n",
        "    \n",
        "    if(min_loss > val_loss):\n",
        "        min_loss = val_loss\n",
        "        val_acc_at_best_epoch = val_acc\n",
        "        top5_acc_at_best_epoch = top5_acc\n",
        "\n",
        "print(f\"Best run ---> val_acc : {val_acc_at_best_epoch:.4f} |\"\n",
        "      f\"Top5_acc : {top5_acc_at_best_epoch:.4f} |\"\n",
        "      f\"val_loss : {min_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "n_WVJStV3QvD"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# 9️⃣ Plot function (can run separately)\n",
        "# ------------------------------\n",
        "def plot_curves_comparison(train_losses1, val_losses1, train_accs1, val_accs1,\n",
        "                           train_losses2, val_losses2, train_accs2, val_accs2):\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # Train Loss Comparison\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(train_losses1, label=\"Model 1 Train Loss\")\n",
        "    plt.plot(train_losses2, label=\"Model 2 Train Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training Loss Comparison\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Validation Loss Comparison\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(val_losses1, label=\"Model 1 Val Loss\")\n",
        "    plt.plot(val_losses2, label=\"Model 2 Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Validation Loss Comparison\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Train Accuracy Comparison\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(train_accs1, label=\"Model 1 Train Acc\")\n",
        "    plt.plot(train_accs2, label=\"Model 2 Train Acc\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Training Accuracy Comparison\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Validation Accuracy Comparison\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(val_accs1, label=\"Model 1 Val Acc\")\n",
        "    plt.plot(val_accs2, label=\"Model 2 Val Acc\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Validation Accuracy Comparison\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "nr-o0SjH9D7w"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_losses1' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[76], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plot_curves_comparison(train_losses, val_losses, train_accs, val_accs,\n\u001b[1;32m----> 2\u001b[0m                            \u001b[43mtrain_losses1\u001b[49m, val_losses1, train_accs1, val_accs1)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'train_losses1' is not defined"
          ]
        }
      ],
      "source": [
        "plot_curves_comparison(train_losses, val_losses, train_accs, val_accs,\n",
        "                           train_losses1, val_losses1, train_accs1, val_accs1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
